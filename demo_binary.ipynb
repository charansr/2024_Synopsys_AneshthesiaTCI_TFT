{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTORCH_ENABLE_MPS_FALLBACK=1\n"
     ]
    }
   ],
   "source": [
    "%env PYTORCH_ENABLE_MPS_FALLBACK=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.utilities import disable_possible_user_warnings\n",
    "disable_possible_user_warnings()\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.*\")\n",
    "import logging\n",
    "logging.getLogger('lightning').setLevel(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charansr/model_training/venv/lib/python3.10/site-packages/pytorch_forecasting/models/base_model.py:30: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from pytorch_forecasting.metrics import MAE, MAPE, MASE, RMSE, SMAPE, MultiHorizonMetric, MultiLoss\n",
    "\n",
    "from collections import namedtuple\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import inspect\n",
    "import logging\n",
    "import os\n",
    "from typing import Any, Callable, Dict, Iterable, List, Literal, Optional, Tuple, Union\n",
    "import warnings\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import LightningModule, Trainer\n",
    "from lightning.pytorch.callbacks import BasePredictionWriter, LearningRateFinder\n",
    "from lightning.pytorch.trainer.states import RunningStage\n",
    "from lightning.pytorch.utilities.parsing import AttributeDict, get_init_args\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.lib.function_base import iterable\n",
    "import pandas as pd\n",
    "import pytorch_optimizer\n",
    "from pytorch_optimizer import Ranger21\n",
    "import scipy.stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import rnn\n",
    "from torch.optim.lr_scheduler import LambdaLR, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.autonotebook import tqdm\n",
    "import yaml\n",
    "from lightning.pytorch.utilities import rank_zero_only\n",
    "\n",
    "from pytorch_forecasting.data import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data.encoders import EncoderNormalizer, GroupNormalizer, MultiNormalizer, NaNLabelEncoder\n",
    "from pytorch_forecasting.metrics import (\n",
    "    MAE,\n",
    "    MASE,\n",
    "    SMAPE,\n",
    "    DistributionLoss,\n",
    "    MultiHorizonMetric,\n",
    "    MultiLoss,\n",
    "    convert_torchmetric_to_pytorch_forecasting_metric,\n",
    "    CrossEntropy\n",
    "    \n",
    ")\n",
    "from pytorch_forecasting.metrics.base_metrics import Metric\n",
    "from pytorch_forecasting.models.nn.embeddings import MultiEmbedding\n",
    "from pytorch_forecasting.utils import (\n",
    "    InitialParameterRepresenterMixIn,\n",
    "    OutputMixIn,\n",
    "    TupleOutputMixIn,\n",
    "    apply_to_list,\n",
    "    concat_sequences,\n",
    "    create_mask,\n",
    "    get_embedding_size,\n",
    "    groupby_apply,\n",
    "    to_list,\n",
    ")\n",
    "from copy import copy\n",
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchmetrics import Accuracy, Metric as LightningMetric\n",
    "\n",
    "from pytorch_forecasting.data import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data.encoders import NaNLabelEncoder\n",
    "from pytorch_forecasting.metrics import MAE, MAPE, MASE, RMSE, SMAPE, MultiHorizonMetric, MultiLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.base_model import BaseModelWithCovariates\n",
    "from pytorch_forecasting.models.nn import LSTM, MultiEmbedding\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.sub_modules import (\n",
    "    AddNorm,\n",
    "    GateAddNorm,\n",
    "    GatedLinearUnit,\n",
    "    GatedResidualNetwork,\n",
    "    InterpretableMultiHeadAttention,\n",
    "    VariableSelectionNetwork,\n",
    ")\n",
    "from pytorch_forecasting.utils import create_mask, detach, integer_histogram, masked_op, padded_stack, to_list\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import statsmodels\n",
    "import random\n",
    "\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting import GroupNormalizer\n",
    "from pytorch_forecasting import Baseline\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from pytorch_forecasting.data.encoders import NaNLabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting import GroupNormalizer\n",
    "from pytorch_forecasting import Baseline\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import pickle\n",
    "import math\n",
    "from pytorch_forecasting.metrics import CrossEntropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#important constants\n",
    "workernum = 4\n",
    "batch_size = 8\n",
    "brave_workers = False\n",
    "pinmem=False\n",
    "marsh_coeff=50\n",
    "schnider_coeff=200\n",
    "eleveld_coeff=100\n",
    "\n",
    "\n",
    "\n",
    "def append_string_to_txt(string_to_append, file_path):\n",
    "    try:\n",
    "        with open(file_path, 'a') as file:\n",
    "            file.write(string_to_append)\n",
    "        #print(f'String appended to {file_path} successfully.')\n",
    "    except Exception as e:\n",
    "        #print(f'Error: {e}')\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df imported\n",
      "dropped\n",
      "dropped\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "final_df = pd.read_csv(\"/Users/charansr/model_training/tuningdf_pkpkd27.csv\")\n",
    "print(\"df imported\")\n",
    "\n",
    "if(\"Unnamed: 0.1\" in final_df.columns):\n",
    "    final_df=final_df.drop(\"Unnamed: 0.1\",axis=1)\n",
    "    print(\"dropped\")\n",
    "\n",
    "if(\"Unnamed: 0\" in final_df.columns):\n",
    "    final_df=final_df.drop(\"Unnamed: 0\",axis=1)\n",
    "    print(\"dropped\")\n",
    "\n",
    "if(\"Unnamed: 0.2\" in final_df.columns):\n",
    "    final_df=final_df.drop(\"Unnamed: 0.2\",axis=1)\n",
    "    print(\"dropped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tar_mean=(final_df[\"Orchestra/PPF20_RATE\"]).mean()\n",
    "tar_std=(final_df[\"Orchestra/PPF20_RATE\"]).std()\n",
    "\n",
    "condition = final_df[\"Orchestra/PPF20_RATE\"] > (tar_mean + (0.5 * tar_std))\n",
    "\n",
    "final_df[\"InfusionSpikes\"]=condition.apply(lambda x: 1 if x else 0)\n",
    "final_df[\"InfusionSpikes\"]=final_df[\"InfusionSpikes\"].astype(\"Int64\")\n",
    "\n",
    "\n",
    "columns=[\"time\",\"caseid\",\"Orchestra/PPF20_CP\",\"Orchestra/PPF20_CT\",\"Orchestra/PPF20_RATE\",\"Orchestra/PPF20_CE\",\"Orchestra/RFTN20_CP\",\"Orchestra/RFTN20_CT\",\"Orchestra/RFTN20_RATE\",\"Orchestra/RFTN20_CE\",\"BIS/BIS\",\"Solar8000/HR\",\"Solar8000/PLETH_SPO2\",\"Solar8000/ART_MBP\",\"Solar8000/ART_SBP\",\"Solar8000/BT\",\"casestart\",\"anestart\",\"opstart\",\"age\",\"sex\",\"height\",\"weight\",\"bmi\",\"asa\",\"optype\",\"dx\",\"opname\",\"ane_type\",\"preop_dm\",\"Marsh\",\"Schnider\",\"Eleveld\",\"InfusionSpikes\"]\n",
    "static_tracks=[\"casestart\",\"anestart\",\"opstart\",\"age\",\"height\",\"weight\",\"bmi\",\"asa\",\"preop_dm\"]\n",
    "static_cat=[\"sex\",\"optype\",\"dx\",\"opname\",\"ane_type\"]\n",
    "time_varying_known=[\"Orchestra/PPF20_CT\",\"Orchestra/RFTN20_CT\",\"Marsh\",\"Schnider\",\"Eleveld\"]\n",
    "time_varying_notknown=[\"Orchestra/PPF20_RATE\",\"Orchestra/PPF20_CP\",\"Orchestra/PPF20_CE\",\"Orchestra/RFTN20_CP\",\"Orchestra/RFTN20_CE\",\"Orchestra/RFTN20_RATE\",\"Solar8000/HR\",\"Solar8000/PLETH_SPO2\",\"Solar8000/ART_MBP\",\"Solar8000/ART_SBP\",\"Solar8000/BT\",\"BIS/BIS\",\"InfusionSpikes\"]\n",
    "\n",
    "\n",
    "\n",
    "final_df.reset_index(drop=True,inplace=True)\n",
    "final_df[static_tracks]=final_df[static_tracks].astype(\"float\")\n",
    "final_df[time_varying_known]=final_df[time_varying_known].astype(\"float\")\n",
    "final_df[time_varying_notknown]=final_df[time_varying_notknown].astype(\"float\")\n",
    "final_df[\"InfusionSpikes\"]=final_df[\"InfusionSpikes\"].astype(int)\n",
    "final_df[\"time\"]=final_df[\"time\"].astype(int)\n",
    "final_df[static_cat]=final_df[static_cat].astype(str)\n",
    "final_df=final_df.dropna()\n",
    "final_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "final_df[\"Marsh\"]=final_df[\"Marsh\"]*marsh_coeff\n",
    "final_df[\"Schnider\"]=final_df[\"Schnider\"]*schnider_coeff\n",
    "final_df[\"Eleveld\"]=final_df[\"Eleveld\"]*eleveld_coeff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3s/hcbtx1hn1cs7zkby2nr_hyp80000gn/T/ipykernel_99786/761977438.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[\"InfusionSpikes\"]=train_df[\"InfusionSpikes\"].astype(\"Int64\")\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/charansr/model_training/train_caseids.pkl\", 'rb') as file:\n",
    "    traincas = pickle.load(file)\n",
    "\n",
    "traincas = [caseid for caseid in traincas]\n",
    "traincas.sort()\n",
    "traincas=traincas[0:3]\n",
    "train_df=final_df[final_df[\"caseid\"].isin(traincas)]\n",
    "\n",
    "#train_df=final_df[final_df[\"caseid\"]==34]\n",
    "train_df[\"InfusionSpikes\"]=train_df[\"InfusionSpikes\"].astype(\"Int64\")\n",
    "\n",
    "with open(\"/Users/charansr/model_training/val_caseids.pkl\", 'rb') as file:\n",
    "    valcas = pickle.load(file)\n",
    "\n",
    "valcas = [caseid for caseid in valcas if caseid < 1008]\n",
    "valcas.sort()\n",
    "valcas=valcas[0:1]\n",
    "val_df=final_df[final_df[\"caseid\"].isin(valcas)]\n",
    "\n",
    "\n",
    "val_df=val_df.reset_index(drop=True)\n",
    "train_df=train_df.reset_index(drop=True)\n",
    "#Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/charansr/model_training/test_caseids.pkl\", 'rb') as file:\n",
    "    testcas = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_prediction_length = 1\n",
    "max_encoder_length = 200\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    train_df,\n",
    "    time_idx=\"time\",\n",
    "    target=\"InfusionSpikes\",\n",
    "    group_ids=[\"caseid\"],\n",
    "    min_encoder_length=max_encoder_length // 2, \n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=static_cat,\n",
    "    static_reals=static_tracks,\n",
    "    time_varying_known_reals=time_varying_known,\n",
    "    time_varying_unknown_reals=time_varying_notknown,\n",
    "    target_normalizer=NaNLabelEncoder(),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=workernum, persistent_workers=brave_workers,pin_memory=pinmem)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validation = TimeSeriesDataSet(\n",
    "    val_df,\n",
    "    time_idx=\"time\",\n",
    "    target=\"InfusionSpikes\",\n",
    "    group_ids=[\"caseid\"],\n",
    "    min_encoder_length=max_encoder_length // 2, \n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=static_cat,\n",
    "    static_reals=static_tracks,\n",
    "    time_varying_known_reals=time_varying_known,\n",
    "    time_varying_unknown_reals=time_varying_notknown,\n",
    "    target_normalizer=NaNLabelEncoder(),  # we normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=workernum, persistent_workers=brave_workers,pin_memory=pinmem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',  # Choose a metric to monitor (e.g., validation loss)\n",
    "    dirpath='/home/sridhar/binary_out_dev1/checkpoints/',  # Directory to save checkpoints\n",
    "    filename='binary_best_model-{epoch:02d}-{val_loss:.2f}',  # Naming pattern for saved checkpoints\n",
    "    save_top_k=1,  # Save only the best model\n",
    "    every_n_epochs=1,\n",
    "    mode='min',  # 'min' if monitoring validation loss, 'max' if monitoring validation accuracy\n",
    ")\n",
    "all_checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='/home/sridhar/binary_out_dev1/checkpoints/',  # Directory to save checkpoints\n",
    "    filename='binary_all_model-{epoch:02d}-{val_loss:.2f}',  # Naming pattern for saved checkpoints\n",
    "    save_top_k=-1,\n",
    "    every_n_epochs=1\n",
    ")\n",
    "\n",
    "\n",
    "class metric_record(pl.callbacks.Callback):\n",
    "    \n",
    "    def on_epoch_start(self, trainer, pl_module):\n",
    "        print(trainer.current_epoch)\n",
    "        newep=str(trainer.current_epoch)\n",
    "        newep+=\"\\n\"\n",
    "        append_string_to_txt(newep,\"/home/sridhar/binary_out_dev1/binary_output.txt\")\n",
    "        #print(pl_module.logging_metrics)\n",
    "        #print(trainer.callback_metrics)\n",
    "        \"\"\"for metric in pl_module.logging_metrics:\n",
    "            metric_name = metric.__class__.__name__\n",
    "            value = trainer.callback_metrics.get(metric_name, None)\n",
    "            print(f'{metric_name}: {value}')\n",
    "            a=f'{metric_name}: {value}\\n'\n",
    "            append_string_to_txt(a,\"binary_output.txt\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class custom_tft(TemporalFusionTransformer):\n",
    "    def log_metrics(\n",
    "        self,\n",
    "        x: Dict[str, torch.Tensor],\n",
    "        y: torch.Tensor,\n",
    "        out: Dict[str, torch.Tensor],\n",
    "        prediction_kwargs: Dict[str, Any] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Log metrics every training/validation step.\n",
    "\n",
    "        Args:\n",
    "            x (Dict[str, torch.Tensor]): x as passed to the network by the dataloader\n",
    "            y (torch.Tensor): y as passed to the loss function by the dataloader\n",
    "            out (Dict[str, torch.Tensor]): output of the network\n",
    "            prediction_kwargs (Dict[str, Any]): parameters for ``to_prediction()`` of the loss metric.\n",
    "        \"\"\"\n",
    "        # logging losses - for each target\n",
    "        if prediction_kwargs is None:\n",
    "            prediction_kwargs = {}\n",
    "        y_hat_point = self.to_prediction(out, **prediction_kwargs)\n",
    "        if isinstance(self.loss, MultiLoss):\n",
    "            y_hat_point_detached = [p.detach() for p in y_hat_point]\n",
    "        else:\n",
    "            y_hat_point_detached = [y_hat_point.detach()]\n",
    "\n",
    "        for metric in self.logging_metrics:\n",
    "            for idx, y_point, y_part, encoder_target in zip(\n",
    "                list(range(len(y_hat_point_detached))),\n",
    "                y_hat_point_detached,\n",
    "                to_list(y[0]),\n",
    "                to_list(x[\"encoder_target\"]),\n",
    "            ):\n",
    "                y_true = (y_part, y[1])\n",
    "                if isinstance(metric, MASE):\n",
    "                    loss_value = metric(\n",
    "                        y_point, y_true, encoder_target=encoder_target, encoder_lengths=x[\"encoder_lengths\"]\n",
    "                    )\n",
    "                else:\n",
    "                    loss_value = metric(y_point, y_true)\n",
    "                if len(y_hat_point_detached) > 1:\n",
    "                    target_tag = self.target_names[idx] + \" \"\n",
    "                else:\n",
    "                    target_tag = \"\"\n",
    "                    \n",
    "                    #CUSTOM PART START\n",
    "                    #print(f\"{target_tag}{self.current_stage}_{metric.name}\",\": \",loss_value)\n",
    "                    save_string = \"{}{}_{}: {}\".format(target_tag, self.current_stage, metric.name, loss_value)\n",
    "                    save_string+=\"\\n\"\n",
    "                    append_string_to_txt(save_string,\"/home/sridhar/binary_out_dev1/binary_output.txt\")\n",
    "                    # CUSTOM PART END\n",
    "                    \n",
    "                    self.log(\n",
    "                    f\"{target_tag}{self.current_stage}_{metric.name}\",\n",
    "                    loss_value,\n",
    "                    on_step=self.training,\n",
    "                    on_epoch=True,\n",
    "                    batch_size=len(x[\"decoder_target\"]),\n",
    "                    sync_dist=True\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class customCrossEntropy(CrossEntropy):\n",
    "    def loss(self, y_pred, target):\n",
    "        loss = F.cross_entropy(y_pred.view(-1, y_pred.size(-1)), target.view(-1), weight=torch.tensor([1.0,1.5],device=\"cuda\"),reduction=\"none\").view(\n",
    "            -1, target.size(-1)\n",
    "        )\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=5, verbose=True, mode=\"min\")\n",
    "logger = TensorBoardLogger(save_dir=\"/home/sridhar/binary_out_dev1\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=45,\n",
    "    accelerator='gpu',\n",
    "    devices=\"auto\",\n",
    "    strategy=\"auto\", \n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.01,\n",
    "    callbacks=[early_stop_callback,best_checkpoint_callback,all_checkpoint_callback,metric_record()],\n",
    "    logger=logger,\n",
    "    log_every_n_steps=50,\n",
    "    accumulate_grad_batches=8,\n",
    "    limit_val_batches=0.2,\n",
    "     limit_train_batches=0.4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charansr/model_training/venv/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/Users/charansr/model_training/venv/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tft = custom_tft.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.01,\n",
    "    hidden_size=160,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=160,\n",
    "    output_size=2,  \n",
    "    loss=customCrossEntropy(),\n",
    "    log_interval=10, \n",
    "    reduce_on_plateau_patience=4,\n",
    "    logging_metrics = nn.ModuleList([SMAPE(), MAE(), RMSE(), MAPE()])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=final_df[final_df[\"caseid\"]== 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charansr/model_training/venv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.4.1.post1 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/charansr/binary_output_anesthesia/checkpoints/binary_best_model-epoch=08-val_loss=0.03.ckpt\"\n",
    "checkpoint=torch.load(path,map_location=torch.device('mps'))\n",
    "tft.load_state_dict(state_dict=checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"lightning.pytorch.utilities.rank_zero\").setLevel(logging.WARNING)\n",
    "mypreds=[]\n",
    "myactual=[]\n",
    "for i in range(0,500):\n",
    "    test_df=final_df[final_df[\"caseid\"]== 14]\n",
    "    test_df=test_df[0+i:202+i]\n",
    "    test_df.reset_index(inplace=True,drop=True)\n",
    "    test = TimeSeriesDataSet(\n",
    "        test_df,\n",
    "        time_idx=\"time\",\n",
    "        target=\"InfusionSpikes\",\n",
    "        group_ids=[\"caseid\"],\n",
    "        min_encoder_length=max_encoder_length // 2, \n",
    "        max_encoder_length=max_encoder_length,\n",
    "        min_prediction_length=1,\n",
    "        max_prediction_length=max_prediction_length,\n",
    "        static_categoricals=static_cat,\n",
    "        static_reals=static_tracks,\n",
    "        time_varying_known_reals=time_varying_known,\n",
    "        time_varying_unknown_reals=time_varying_notknown,\n",
    "        target_normalizer=NaNLabelEncoder(),\n",
    "        add_relative_time_idx=True,\n",
    "        add_target_scales=True,\n",
    "        add_encoder_length=True,\n",
    "        allow_missing_timesteps=True\n",
    "    )\n",
    "    test_dataloader = test.to_dataloader(train=False, batch_size=1, num_workers=1, persistent_workers=False,pin_memory=False)\n",
    "    predictions = tft.predict(test_dataloader, return_y=True, fast_dev_run=True,trainer_kwargs=dict(accelerator=\"mps\"))\n",
    "    mypreds+=[predictions.output.item()]\n",
    "    myactual+=[predictions.y[0].item()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2fad86380>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(myactual)\n",
    "plt.plot(mypreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
